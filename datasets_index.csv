Project,Task,Dataset name,Webpage,URL(s),project_key,task_key,available
Emergent Languages,Image classification,fashion-mnist,https://github.com/zalandoresearch/fashion-mnist,http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz;http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz;http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz;http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,places-365,https://github.com/CSAILVision/places365 ,http://data.csail.mit.edu/places/places365/train_large_places365standard.tar;http://data.csail.mit.edu/places/places365/val_large.tar;http://data.csail.mit.edu/places/places365/test_large.tar,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,inaturalist,https://github.com/visipedia/inat_comp ,https://ml-inat-competition-datasets.s3.amazonaws.com/2021/train.tar.gz;https://ml-inat-competition-datasets.s3.amazonaws.com/2021/train.json.tar.gz;https://ml-inat-competition-datasets.s3.amazonaws.com/2021/val.tar.gz;https://ml-inat-competition-datasets.s3.amazonaws.com/2021/val.json.tar.gz;https://ml-inat-competition-datasets.s3.amazonaws.com/2021/public_test.tar.gz;https://ml-inat-competition-datasets.s3.amazonaws.com/2021/public_test.json.tar.gz,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,qmnist,https://github.com/facebookresearch/qmnist ,manual,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,kmnist,https://github.com/rois-codh/kmnist ,http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz;http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz;http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz;http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,svhn,http://ufldl.stanford.edu/housenumbers/ ,http://ufldl.stanford.edu/housenumbers/train_32x32.mat;http://ufldl.stanford.edu/housenumbers/test_32x32.mat;http://ufldl.stanford.edu/housenumbers/extra_32x32.mat,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,caltech-101,http://www.vision.caltech.edu/Image_Datasets/Caltech101/ ,http://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz;http://www.vision.caltech.edu/Image_Datasets/Caltech101/Annotations.tar,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,caltech-256,http://www.vision.caltech.edu/Image_Datasets/Caltech256/ ,http://www.vision.caltech.edu/Image_Datasets/Caltech256/256_ObjectCategories.tar,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,food-101,https://www.kaggle.com/dansbecker/food-101,manual,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,sun-database,https://vision.princeton.edu/projects/2010/SUN/,http://vision.princeton.edu/projects/2010/SUN/SUN397.tar.gz,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,cars,http://ai.stanford.edu/~jkrause/cars/car_dataset.html,http://ai.stanford.edu/~jkrause/car196/cars_train.tgz;http://ai.stanford.edu/~jkrause/car196/cars_test.tgz;https://ai.stanford.edu/~jkrause/cars/car_devkit.tgz,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,fgvc-aircraft,https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/,https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/archives/fgvc-aircraft-2013b.tar.gz,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,pascal-voc2007,http://host.robots.ox.ac.uk/pascal/VOC/voc2007/,http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar;http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,describable-textures,https://www.robots.ox.ac.uk/~vgg/data/dtd/,https://www.robots.ox.ac.uk/~vgg/data/dtd/download/dtd-r1.0.1.tar.gz,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,oxford-pet,https://www.robots.ox.ac.uk/~vgg/data/pets/,https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz;https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,animals-attributes,https://cvml.ist.ac.at/AwA2/,https://cvml.ist.ac.at/AwA2/AwA2-data.zip;https://cvml.ist.ac.at/AwA2/AwA2-base.zip;http://cvml.ist.ac.at/AwA2/AwA2-features.zip,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,celeba,http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html,manual,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,cub-200-2011,http://www.vision.caltech.edu/visipedia/CUB-200-2011.html,http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/CUB_200_2011.tgz,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,oxford-102-flower,https://www.robots.ox.ac.uk/~vgg/data/flowers/102/,https://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz;https://www.robots.ox.ac.uk/~vgg/data/flowers/102/imagelabels.mat;https://www.robots.ox.ac.uk/~vgg/data/flowers/102/setid.mat,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,abstract-reasoning,https://github.com/deepmind/abstract-reasoning-matrices,https://storage.googleapis.com/ravens-matrices/attr.rel.pairs.tar.gz;https://storage.googleapis.com/ravens-matrices/attr.rels.tar.gz;https://storage.googleapis.com/ravens-matrices/attrs.line.type.tar.gz;https://storage.googleapis.com/ravens-matrices/attrs.pairs.tar.gz;https://storage.googleapis.com/ravens-matrices/attrs.shape.color.tar.gz;https://storage.googleapis.com/ravens-matrices/extrapolation.tar.gz;https://storage.googleapis.com/ravens-matrices/interpolation.tar.gz;https://storage.googleapis.com/ravens-matrices/neutral.tar.gz,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,extended-yale-b,http://vision.ucsd.edu/~leekc/ExtYaleDatabase/ExtYaleB.html,http://vision.ucsd.edu/extyaleb/CroppedYaleBZip/CroppedYale.zip,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,emnist,https://www.nist.gov/itl/products-and-services/emnist-dataset,http://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,clothing-1m,https://github.com/Cysu/noisy_label,manual,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,yfcc-100m,http://www.multimediacommons.org/,http://multimedia-commons.s3-website-us-west-2.amazonaws.com/,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,minc,http://opensurfaces.cs.cornell.edu/publications/minc/,http://opensurfaces.cs.cornell.edu/static/minc/minc-2500.tar.gz,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,objectnet,https://objectnet.dev/,https://objectnet.dev/downloads/objectnet-1.0.zip,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,plant-village,https://www.kaggle.com/emmarex/plantdisease,manual,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,stanford-dogs,http://vision.stanford.edu/aditya86/ImageNetDogs/,http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar;http://vision.stanford.edu/aditya86/ImageNetDogs/annotation.tar;http://vision.stanford.edu/aditya86/ImageNetDogs/lists.tar,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,ut-zappos-50k,https://vision.cs.utexas.edu/projects/finegrained/utzap50k/,https://vision.cs.utexas.edu/projects/finegrained/utzap50k/ut-zap50k-images-square.zip;https://vision.cs.utexas.edu/projects/finegrained/utzap50k/ut-zap50k-feats.zip;https://vision.cs.utexas.edu/projects/finegrained/utzap50k/ut-zap50k-data.zip,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,fashion-net,https://docs.google.com/forms/d/e/1FAIpQLScJ_YKcCtE2zJ5F1DTGdAQXvbzKVHLGKiB4bSXNWnEf9Ci2zA/viewform,manual,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,figr-8,https://github.com/marcdemers/FIGR-8,https://github.com/marcdemers/FIGR-8.git,emergent-languages,image-classification,TRUE
Emergent Languages,Image classification,large-labelled-logo,https://lhf.ai/tm-dataset/,https://zenodo.org/record/5771006/files/L3D%20dataset.tar?download=1,emergent-languages,image-classification,TRUE
Emergent Languages,Image reconstruction,afhq,https://github.com/clovaai/stargan-v2,https://www.dropbox.com/s/scckftx13grwmiv/afhq_v2.zip?dl=0,emergent-languages,image-reconstruction,TRUE
Point Cloud,3D Point Cloud Semantic Segmentation,semantic-kitti,http://www.semantic-kitti.org,http://www.cvlibs.net/download.php?file=data_odometry_velodyne.zip;http://www.cvlibs.net/download.php?file=data_odometry_calib.zip;http://www.semantic-kitti.org/assets/data_odometry_labels.zip,point-cloud,3d-point-cloud-semantic-segmentation,TRUE
Point Cloud,3D Point Cloud Semantic Segmentation,sensat-urban,https://github.com/QingyongHu/SensatUrban,manual,point-cloud,3d-point-cloud-semantic-segmentation,TRUE
Point Cloud,3D Point Cloud Semantic Segmentation,partnet,https://partnet.cs.stanford.edu,http://download.cs.stanford.edu/orion/partnet_dataset/data_v0.zip;http://download.cs.stanford.edu/orion/partnet_dataset/sem_seg_h5.zip;http://download.cs.stanford.edu/orion/partnet_dataset/ins_seg_h5.zip,point-cloud,3d-point-cloud-semantic-segmentation,TRUE
Point Cloud,3D Point Cloud Semantic Segmentation,s3dis,http://buildingparser.stanford.edu/dataset.html,manual,point-cloud,3d-point-cloud-semantic-segmentation,TRUE
Point Cloud,3D Point Cloud Semantic Segmentation,rellis-3d,https://github.com/unmannedlab/RELLIS-3D ,https://drive.google.com/file/d/1lDSVRf_kZrD0zHHMsKJ0V1GN9QATR4wH/view?usp=sharing,point-cloud,3d-point-cloud-semantic-segmentation,TRUE
Point Cloud,3D Point Cloud Semantic Segmentation,paris-lille-3d,https://npm3d.fr/paris-lille-3d,manual,point-cloud,3d-point-cloud-semantic-segmentation,TRUE
Point Cloud,3D Point Cloud Semantic Segmentation,paris-carla-3d,https://npm3d.fr/paris-carla-3d,manual,point-cloud,3d-point-cloud-semantic-segmentation,TRUE
Point Cloud,3D Point Cloud Semantic Segmentation,kitti-carla,https://npm3d.fr/kitti-carla,https://cloud.mines-paristech.fr/index.php/s/PtZ73svnktlQE50/download?path=%2Fdataset&files=Town01.zip;https://cloud.mines-paristech.fr/index.php/s/PtZ73svnktlQE50/download?path=%2Fdataset&files=Town02.zip;https://cloud.mines-paristech.fr/index.php/s/PtZ73svnktlQE50/download?path=%2Fdataset&files=Town03.zip;https://cloud.mines-paristech.fr/index.php/s/PtZ73svnktlQE50/download?path=%2Fdataset&files=Town04.zip;https://cloud.mines-paristech.fr/index.php/s/PtZ73svnktlQE50/download?path=%2Fdataset&files=Town05.zip;https://cloud.mines-paristech.fr/index.php/s/PtZ73svnktlQE50/download?path=%2Fdataset&files=Town06.zip;https://cloud.mines-paristech.fr/index.php/s/PtZ73svnktlQE50/download?path=%2Fdataset&files=Town07.zip,point-cloud,3d-point-cloud-semantic-segmentation,TRUE
Point Cloud,3D Point Cloud Semantic Segmentation,semantic-poss,http://www.poss.pku.edu.cn/semanticposs.html,http://www.poss.pku.edu.cn/OpenDataResource/SemanticPOSS/SemanticPOSS_dataset.zip,point-cloud,3d-point-cloud-semantic-segmentation,TRUE
Point Cloud,3D Point Cloud Semantic Segmentation,nuscenes,https://www.nuscenes.org ,manual,point-cloud,3d-point-cloud-semantic-segmentation,TRUE
Point Cloud,3D Point Cloud Semantic Segmentation,swiss-3d-cities,https://github.com/NomokoAG/Swiss3DCities ,manual,point-cloud,3d-point-cloud-semantic-segmentation,TRUE
Point Cloud,3D Point Cloud Semantic Segmentation,buildingnet,https://buildingnet.org ,manual,point-cloud,3d-point-cloud-semantic-segmentation,TRUE
Point Cloud,3D Point Cloud Semantic Segmentation,toronto-3d,https://github.com/WeikaiTan/Toronto-3D,manual,point-cloud,3d-point-cloud-semantic-segmentation,TRUE
Point Cloud,3D Point Cloud Semantic Segmentation,sun-rgbd,https://rgbd.cs.princeton.edu/,https://rgbd.cs.princeton.edu/data/SUNRGBD.zip;https://rgbd.cs.princeton.edu/code/holisticScene.zip;https://rgbd.cs.princeton.edu/code/detection.zip;https://rgbd.cs.princeton.edu/code/roomlayout.zip,point-cloud,3d-point-cloud-semantic-segmentation,TRUE
Point Cloud,3D Point Cloud Classification,modelnet40,https://modelnet.cs.princeton.edu ,http://modelnet.cs.princeton.edu/ModelNet40.zip,point-cloud,3d-point-cloud-classification,TRUE
Point Cloud,3D Point Cloud Classification,intra,https://github.com/intra3d2019/IntrA ,manual,point-cloud,3d-point-cloud-classification,TRUE
Point Cloud,3D Point Cloud Classification,scanobjectnn,https://hkust-vgd.github.io/scanobjectnn/ ,http://hkust-vgd.ust.hk/scanobjectnn/h5_files.zip;http://hkust-vgd.ust.hk/scanobjectnn/raw/object_dataset_complete_with_parts%20.zip;http://hkust-vgd.ust.hk/scanobjectnn/raw/object_dataset_indices.zip;http://hkust-vgd.ust.hk/scanobjectnn/raw/check.txt,point-cloud,3d-point-cloud-classification,TRUE
Point Cloud,3D Point Cloud Classification,sydney-urban-objects,http://www.acfr.usyd.edu.au/papers/SydneyUrbanObjectsDataset.shtml,http://www.acfr.usyd.edu.au/papers/SydneyUrbanObjectsDataset.shtml,point-cloud,3d-point-cloud-classification,TRUE
Point Cloud,3D Point Cloud Classification,shapenet,https://www.shapenet.org ,https://shapenet.cs.stanford.edu/shapenet/obj-zip/ShapeNetCore.v2.zip,point-cloud,3d-point-cloud-classification,TRUE
Point Cloud,3D Point Cloud Classification,scannet,http://www.scan-net.org/,manual,point-cloud,3d-point-cloud-classification,TRUE
Point Cloud,3D Point Cloud Reconstruction,dtu-mvs,http://roboimagedata.compute.dtu.dk/?page_id=36,http://roboimagedata2.compute.dtu.dk/data/MVS/Points_MVS.zip,point-cloud,3d-point-cloud-reconstruction,TRUE
Point Cloud,3D Point Cloud Reconstruction,waymo-perception,https://waymo.com/open/download/,manual,point-cloud,3d-point-cloud-reconstruction,TRUE
Point Cloud,3D Point Cloud Reconstruction,agroverse,https://www.argoverse.org/data.html,https://s3.amazonaws.com/argoai-argoverse/tracking_train1_v1.1.tar.gz;https://s3.amazonaws.com/argoai-argoverse/tracking_train2_v1.1.tar.gz;https://s3.amazonaws.com/argoai-argoverse/tracking_train3_v1.1.tar.gz;https://s3.amazonaws.com/argoai-argoverse/tracking_train4_v1.1.tar.gz;https://s3.amazonaws.com/argoai-argoverse/tracking_val_v1.1.tar.gz;https://s3.amazonaws.com/argoai-argoverse/tracking_test_v1.1.tar.gz,point-cloud,3d-point-cloud-reconstruction,TRUE
Point Cloud,3D Point Cloud Reconstruction,lyft,https://level-5.global/download/,https://lyft-l5-datasets-public.s3-us-west-2.amazonaws.com/3d-object-detection/one_scene.tar;https://lyft-l5-datasets-public.s3-us-west-2.amazonaws.com/3d-object-detection/train.tar;https://lyft-l5-datasets-public.s3-us-west-2.amazonaws.com/3d-object-detection/test.tar,point-cloud,3d-point-cloud-reconstruction,TRUE
Music Generation,Symbolic (MIDI),adl,https://github.com/lucasnfe/adl-piano-midi,manual,music-generation,symbolic-midi,TRUE
Music Generation,Symbolic (MIDI),giantmidis,https://github.com/bytedance/GiantMIDI-Piano,manual,music-generation,symbolic-midi,TRUE
Music Generation,Symbolic (MIDI),hymnal,https://salu133445.github.io/muspy/datasets/datasets.html ,manual,music-generation,symbolic-midi,TRUE
Music Generation,Symbolic (MIDI),hymnaltune,https://salu133445.github.io/muspy/datasets/datasets.html ,manual,music-generation,symbolic-midi,TRUE
Music Generation,Symbolic (MIDI),jsb,https://archive.ics.uci.edu/ml/datasets/Bach+Chorales ,manual,music-generation,symbolic-midi,TRUE
Music Generation,Symbolic (MIDI),lmd,https://colinraffel.com/projects/lmd/,manual,music-generation,symbolic-midi,TRUE
Music Generation,Symbolic (MIDI),maestro,https://magenta.tensorflow.org/datasets/maestro,manual,music-generation,symbolic-midi,TRUE
Music Generation,Symbolic (MIDI),midiman,https://www.reddit.com/r/WeAreTheMusicMakers/comments/3ajwe4/the_largest_midi_collection_on_the_internet/,manual,music-generation,symbolic-midi,TRUE
Music Generation,Symbolic (MIDI),musedata,http://musedata.stanford.edu/,manual,music-generation,symbolic-midi,TRUE
Music Generation,Symbolic (MIDI),music21,https://web.mit.edu/music21/doc/about/referenceCorpus.html,manual,music-generation,symbolic-midi,TRUE
Music Generation,Symbolic (MIDI),musicai,https://composing.ai/dataset,manual,music-generation,symbolic-midi,TRUE
Music Generation,Symbolic (MIDI),vgmdb,https://drive.google.com/drive/folders/1IW83MmH-RJ81yog6sbOUOTHimobE4FuK?usp=sharing,manual,music-generation,symbolic-midi,TRUE
Music Generation,Symbolic (MIDI),doug-mackenzie-jazz,https://drive.google.com/drive/folders/1wVVDpcov5VV6Govhn1-CT0BOifqoF-Od?usp=sharing ,manual,music-generation,symbolic-midi,TRUE
Music Generation,Symbolic (MIDI),musicnet,https://www.kaggle.com/imsparsh/musicnet-dataset?select=musicnet_midis,manual,music-generation,symbolic-midi,TRUE
Music Generation,Symbolic (MIDI),nes,https://github.com/chrisdonahue/nesmdb,manual,music-generation,symbolic-midi,TRUE
Music Generation,Symbolic (MIDI),nottingham,https://ifdo.ca/~seymour/nottingham/nottingham.html,manual,music-generation,symbolic-midi,TRUE
Music Generation,Symbolic (MIDI),groove-midi,https://magenta.tensorflow.org/datasets/groove#download,https://storage.googleapis.com/magentadata/datasets/groove/groove-v1.0.0-midionly.zip,music-generation,symbolic-midi,TRUE
Music Generation,Symbolic (MIDI),expanded-groove-midi,https://magenta.tensorflow.org/datasets/e-gmd#download,https://storage.googleapis.com/magentadata/datasets/e-gmd/v1.0.0/e-gmd-v1.0.0-midi.zip,music-generation,symbolic-midi,TRUE
Music Generation,Symbolic (MIDI),emopia,https://annahung31.github.io/EMOPIA/,manual,music-generation,symbolic-midi,TRUE
Music Generation,Symbolic (MIDI),children-song,https://zenodo.org/record/4785016#.Ye5QeVjMJb_,manual,music-generation,symbolic-midi,TRUE
Music Generation,Audio,fma,https://github.com/mdeff/fma ,https://os.unil.cloud.switch.ch/fma/fma_large.zip,music-generation,audio,TRUE
Efficient Transformers,Multi,lra,https://github.com/google-research/long-range-arena,https://storage.googleapis.com/long-range-arena/lra_release.gz,efficient-transformers,multi,TRUE